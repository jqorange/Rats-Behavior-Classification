import torch
import numpy as np
import os
import glob
import re
from utils.trainer import FusionTrainer
from utils.data_loader import DataLoader  # ä½¿ç”¨ä¹‹å‰åˆ›å»ºçš„æ•°æ®åŠ è½½å™¨


class TrainPipline:
    def __init__(self, data_path, save_path, session_names, N_feat_IMU, N_feat_DLC, num_classes,spilit_num, device='auto', max_samples_per_session=None):
        """
        åˆå§‹åŒ–çœŸå®æ•°æ®è®­ç»ƒå™¨

        Args:
            data_path (str): æ•°æ®è·¯å¾„
            device (str): è®¾å¤‡é€‰æ‹© ('auto', 'cuda', 'cpu')
            max_samples_per_session (int): æ¯ä¸ªsessionæœ€å¤§æ ·æœ¬æ•°ï¼Œç”¨äºå‡å°‘å†…å­˜ä½¿ç”¨
        """
        self.data_path = data_path
        self.save_path = save_path
        self.device = self._setup_device(device)
        self.max_samples_per_session = max_samples_per_session

        # æ•°æ®å‚æ•°
        self.N_feat_IMU = N_feat_IMU
        self.N_feat_DLC = N_feat_DLC
        self.num_classes = num_classes  # æ ¹æ®ä½ çš„å®é™…ç±»åˆ«æ•°è°ƒæ•´

        # ä¼šè¯åç§°
        self.session_names = session_names

        # è®­ç»ƒå’Œæµ‹è¯•ä¼šè¯åˆ’åˆ†
        self.train_sessions = self.session_names[:spilit_num]  # å‰5ä¸ªsessionç”¨äºè®­ç»ƒ
        self.test_sessions = self.session_names[spilit_num:]  # æœ€å1ä¸ªsessionç”¨äºæµ‹è¯•

        # åˆå§‹åŒ–æ•°æ®åŠ è½½å™¨
        self.data_loader = DataLoader(self.session_names, data_path)

        print(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
        print(f"è®­ç»ƒä¼šè¯: {self.train_sessions}")
        print(f"æµ‹è¯•ä¼šè¯: {self.test_sessions}")
        if max_samples_per_session:
            print(f"æ¯ä¸ªsessionæœ€å¤§æ ·æœ¬æ•°: {max_samples_per_session:,}")

    def _setup_device(self, device):
        """è®¾ç½®è®¡ç®—è®¾å¤‡"""
        if device == 'auto':
            device = 'cuda' if torch.cuda.is_available() else 'cpu'

        if device == 'cuda' and not torch.cuda.is_available():
            print("âš ï¸ CUDAä¸å¯ç”¨ï¼Œæ”¹ç”¨CPU")
            device = 'cpu'

        return device

    def load_and_prepare_data(self):
        """åŠ è½½å¹¶å‡†å¤‡è®­ç»ƒæ•°æ®ï¼ˆå¯¹é½å„æ¨¡æ€é•¿åº¦ï¼Œå¹¶é™åˆ¶æœ€å¤§æ ·æœ¬æ•°ï¼Œæ— éšæœºé‡‡æ ·ï¼‰"""
        print("\n=== åŠ è½½æ•°æ® ===")

        # åŠ è½½æ‰€æœ‰æ•°æ®
        self.data_loader.load_all_data()

        def prepare_session(data_dicts, session, desc):
            """
            å¯¹å•ä¸ª session çš„æ•°æ®åšå¯¹é½å’Œæˆªæ–­ã€‚
            data_dicts: æ¨¡æ€æ•°æ®å­—å…¸åˆ—è¡¨ï¼Œå¦‚ [train_IMU, train_DLC, ...]
            è¿”å›ï¼šæˆªæ–­åçš„æ•°ç»„åˆ—è¡¨ï¼Œæˆ– Noneï¼ˆæ•°æ®ç¼ºå¤±ï¼‰
            """
            arrays = []
            # è¯»å–å¹¶æ£€æŸ¥åŸå§‹æ•°æ®
            for d in data_dicts:
                arr = d.get(session)
                if arr is None or len(arr) == 0:
                    return None
                arrays.append(arr.astype(np.float32))
            # å¯¹é½åˆ°æœ€å°é•¿åº¦
            min_len = min(len(a) for a in arrays)
            # é™åˆ¶æœ€å¤§æ ·æœ¬æ•°
            if self.max_samples_per_session:
                min_len = min(min_len, self.max_samples_per_session)
            # æˆªæ–­æ‰€æœ‰æ•°ç»„
            truncated = [a[:min_len] for a in arrays]
            shapes = ", ".join(str(t.shape) for t in truncated)
            print(f"âœ“ {session} ({desc}): æˆªæ–­åé•¿åº¦={min_len}, å½¢çŠ¶={shapes}")
            return truncated

        # â€”â€”â€” æ— ç›‘ç£è®­ç»ƒæ•°æ® â€”â€”â€”
        train_IMU_list, train_DLC_list = [], []
        self.unsup_by_session = {}
        for session in self.train_sessions:
            out = prepare_session(
                [self.data_loader.train_IMU, self.data_loader.train_DLC],
                session, "æ— ç›‘ç£ IMU/DLC"
            )
            if out:
                imu, dlc = out
                train_IMU_list.append(imu)
                train_DLC_list.append(dlc)
                self.unsup_by_session[session] = (imu, dlc)
        if not train_IMU_list:
            raise ValueError("æ²¡æœ‰æ‰¾åˆ°æ— ç›‘ç£è®­ç»ƒæ•°æ®")
        self.train_data_IMU = np.concatenate(train_IMU_list, axis=0)
        self.train_data_DLC = np.concatenate(train_DLC_list, axis=0)
        print(f"åˆå¹¶åæ— ç›‘ç£æ•°æ®: IMU {self.train_data_IMU.shape}, DLC {self.train_data_DLC.shape}")

        # â€”â€”â€” ç›‘ç£è®­ç»ƒæ•°æ® â€”â€”â€”
        sup_IMU_list, sup_DLC_list, sup_labels_list = [], [], []
        self.sup_by_session = {}
        for session in self.train_sessions:
            out = prepare_session(
                [self.data_loader.train_sup_IMU,
                 self.data_loader.train_sup_DLC,
                 self.data_loader.train_labels],
                session, "ç›‘ç£ IMU/DLC/Labels"
            )
            if out:
                imu, dlc, labels = out
                sup_IMU_list.append(imu)
                sup_DLC_list.append(dlc)
                sup_labels_list.append(labels)
                self.sup_by_session[session] = (imu, dlc, labels)

        if sup_IMU_list:
            self.train_sup_IMU = np.concatenate(sup_IMU_list, axis=0)
            self.train_sup_DLC = np.concatenate(sup_DLC_list, axis=0)
            self.train_labels = np.concatenate(sup_labels_list, axis=0)
            print(
                f"åˆå¹¶åç›‘ç£æ•°æ®: IMU {self.train_sup_IMU.shape}, DLC {self.train_sup_DLC.shape}, Labels {self.train_labels.shape}")
        else:
            print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°ç›‘ç£è®­ç»ƒæ•°æ®")
            self.train_sup_IMU = np.empty((0, 0), dtype=np.float32)
            self.train_sup_DLC = np.empty((0, 0), dtype=np.float32)
            self.train_labels = np.empty((0,), dtype=np.float32)

        # â€”â€”â€” æµ‹è¯•æ•°æ® â€”â€”â€”
        test_IMU_list, test_DLC_list, test_labels_list = [], [], []
        for session in self.test_sessions:
            out = prepare_session(
                [self.data_loader.train_sup_IMU,
                 self.data_loader.train_sup_DLC,
                 self.data_loader.train_labels],
                session, "æµ‹è¯• IMU/DLC/Labels"
            )
            if out:
                imu, dlc, labels = out
                test_IMU_list.append(imu)
                test_DLC_list.append(dlc)
                test_labels_list.append(labels)

        if test_IMU_list:
            self.test_data_IMU = np.concatenate(test_IMU_list, axis=0)
            self.test_data_DLC = np.concatenate(test_DLC_list, axis=0)
            self.test_labels = np.concatenate(test_labels_list, axis=0)
            print(
                f"åˆå¹¶åæµ‹è¯•æ•°æ®: IMU {self.test_data_IMU.shape}, DLC {self.test_data_DLC.shape}, Labels {self.test_labels.shape}")
        else:
            print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°æµ‹è¯•æ•°æ®")
            self.test_data_IMU = np.empty((0, 0), dtype=np.float32)
            self.test_data_DLC = np.empty((0, 0), dtype=np.float32)
            self.test_labels = np.empty((0,), dtype=np.float32)

        return True

    def initialize_trainer(self, **kwargs):
        """åˆå§‹åŒ–FusionTrainer"""
        print("\n=== åˆå§‹åŒ–æ¨¡å‹ ===")

        # é»˜è®¤å‚æ•°
        default_params = {
            'N_feat_A': self.N_feat_IMU,
            'N_feat_B': self.N_feat_DLC,
            'num_classes': self.num_classes,
            'mask_type': 'binomial',
            'd_model': 128,
            'nhead': 8,
            'hidden_dim': 256,
            'device': self.device,
            'lr_encoder': 0.0001,
            'lr_classifier': 0.001,
            'batch_size': 32,
            'temporal_unit': 1,
            'contrastive_epochs': 50,
            'mlp_epochs': 100,
            'save_path': self.save_path,
            'save_gap': 3,
            'n_stable': 1,
            'n_adapted': 2,
            'n_all': 3,
            'use_amp': False
        }

        # æ›´æ–°å‚æ•°
        default_params.update(kwargs)

        # åˆ›å»ºè®­ç»ƒå™¨
        self.trainer = FusionTrainer(**default_params)

        print(f"æ¨¡å‹å‚æ•°æ•°é‡:")
        print(f"  - Encoder: {sum(p.numel() for p in self.trainer.encoder_fusion.parameters()):,}")


        return self.trainer

    def test_model_components(self):
        """æµ‹è¯•æ¨¡å‹ç»„ä»¶"""
        print("\n=== æµ‹è¯•æ¨¡å‹ç»„ä»¶ ===")

        # æµ‹è¯•ç¼–ç å™¨
        self.trainer.encoder_fusion.eval()
        with torch.no_grad():
            # ä½¿ç”¨çœŸå®æ•°æ®çš„ä¸€å°éƒ¨åˆ†è¿›è¡Œæµ‹è¯•
            test_size = min(2, len(self.train_data_IMU))
            test_length = min(50, self.train_data_IMU.shape[1])

            test_IMU = torch.tensor(self.train_data_IMU[:test_size, :test_length]).to(self.device)
            test_DLC = torch.tensor(self.train_data_DLC[:test_size, :test_length]).to(self.device)

            test_output = self.trainer.encoder_fusion(test_IMU, test_DLC)
            print(f"âœ“ ç¼–ç å™¨æµ‹è¯•é€šè¿‡: è¾“å…¥IMU {test_IMU.shape}, DLC {test_DLC.shape} -> è¾“å‡º {test_output.shape}")
            print(f"  è¾“å‡ºèŒƒå›´: [{test_output.min():.4f}, {test_output.max():.4f}]")

        self.trainer.encoder_fusion.train()

    def train_model(self, start_epoch=0, verbose=True):
        """è®­ç»ƒæ¨¡å‹"""
        print("\n=== å¼€å§‹è®­ç»ƒ ===")

        try:
            # æ£€æŸ¥æ•°æ®
            if len(self.train_sup_IMU) == 0:
                print("âš ï¸ æ²¡æœ‰ç›‘ç£æ•°æ®ï¼Œåªè¿›è¡Œæ— ç›‘ç£è®­ç»ƒ")
                train_sup_IMU = None
                train_sup_DLC = None
                train_labels = None
            else:
                train_sup_IMU = self.train_sup_IMU
                train_sup_DLC = self.train_sup_DLC
                train_labels = self.train_labels

            if len(self.test_data_IMU) == 0:
                print("âš ï¸ æ²¡æœ‰æµ‹è¯•æ•°æ®ï¼Œè·³è¿‡æµ‹è¯•è¯„ä¼°")
                test_data_IMU = None
                test_data_DLC = None
                test_labels = None
            else:
                test_data_IMU = self.test_data_IMU
                test_data_DLC = self.test_data_DLC
                test_labels = self.test_labels

            # è®­ç»ƒæ¨¡å‹
            losses = self.trainer.fit(
                unsup_sessions=self.unsup_by_session,
                train_data_A=self.train_data_IMU,
                train_data_B=self.train_data_DLC,
                train_data_sup_A=train_sup_IMU,
                train_data_sup_B=train_sup_DLC,
                labels_sup=train_labels,
                test_data_A=test_data_IMU,
                test_data_B=test_data_DLC,
                test_labels=test_labels,
                verbose=verbose,
                start_epoch=start_epoch
            )

            print("\n=== è®­ç»ƒå®Œæˆ ===")
            print(f"å¯¹æ¯”å­¦ä¹ æŸå¤±å†å²: {len(losses['contrastive'])} ä¸ªepoch")


            return losses

        except Exception as e:
            print(f"âŒ è®­ç»ƒå¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return None

    def evaluate_model(self):
        """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
        print("\n=== æ¨¡å‹è¯„ä¼° ===")

        if len(self.test_data_IMU) == 0:
            print("âš ï¸ æ²¡æœ‰æµ‹è¯•æ•°æ®ï¼Œè·³è¿‡è¯„ä¼°")
            return None

        try:
            # é¢„æµ‹
            predictions = self.trainer.predict(self.test_data_IMU, self.test_data_DLC)

            print(f"é¢„æµ‹ç»“æœå½¢çŠ¶: {predictions.shape}")
            print(f"çœŸå®æ ‡ç­¾å½¢çŠ¶: {self.test_labels.shape}")

            # å¦‚æœæœ‰æ—¶é—´ç»´åº¦ï¼Œå–å¹³å‡
            if predictions.ndim == 3:  # (N, T, C)
                predictions_avg = predictions.mean(axis=1)  # (N, C)
            else:
                predictions_avg = predictions

            # è®¡ç®—å‡†ç¡®ç‡ï¼ˆå¦‚æœæ˜¯å¤šæ ‡ç­¾åˆ†ç±»ï¼‰
            if self.test_labels.ndim == 2:  # å¤šæ ‡ç­¾
                pred_binary = (predictions_avg > 0.5).astype(int)
                accuracy = (pred_binary == self.test_labels).mean()
                print(f"å¤šæ ‡ç­¾å‡†ç¡®ç‡: {accuracy:.4f}")

                # æ¯ä¸ªç±»åˆ«çš„å‡†ç¡®ç‡
                for i in range(self.num_classes):
                    class_acc = (pred_binary[:, i] == self.test_labels[:, i]).mean()
                    print(f"  ç±»åˆ« {i}: {class_acc:.4f}")

            return predictions_avg

        except Exception as e:
            print(f"âŒ è¯„ä¼°å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return None

    def run_full_pipeline(self, resume=True, **trainer_kwargs):
        """è¿è¡Œå®Œæ•´çš„è®­ç»ƒæµæ°´çº¿

        Args:
            resume (bool): Whether to resume from the latest checkpoint
        """
        """è¿è¡Œå®Œæ•´çš„è®­ç»ƒæµæ°´çº¿"""
        print("ğŸš€ å¼€å§‹å®Œæ•´è®­ç»ƒæµæ°´çº¿...")
        print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
        print(f"è®¾å¤‡: {self.device}")

        try:
            # 1. åŠ è½½æ•°æ®
            self.load_and_prepare_data()

            # 2. åˆå§‹åŒ–æ¨¡å‹
            self.initialize_trainer(**trainer_kwargs)
            if resume:
                pattern = os.path.join(self.save_path, "encoder_*.pkl")
                checkpoints = glob.glob(pattern)
                max_cycle = -1
                for ckpt in checkpoints:
                    m = re.search(r"encoder_(\d+)\.pkl", os.path.basename(ckpt))
                    if m:
                        num = int(m.group(1))
                        if num > max_cycle:
                            max_cycle = num
                if max_cycle >= 0:
                    print(f"Resuming from checkpoint epoch {max_cycle}")
                    self.trainer.load(max_cycle)
                    start_epoch = max_cycle + 1
            else:
                start_epoch = 0

                # 3. æµ‹è¯•æ¨¡å‹ç»„ä»¶
            self.test_model_components()

            # 4. è®­ç»ƒæ¨¡å‹
            losses = self.train_model(start_epoch=start_epoch)

            if losses is None:
                print("âŒ è®­ç»ƒå¤±è´¥")
                return False


            print("\n" + "=" * 60)
            print("ğŸ‰ è®­ç»ƒæµæ°´çº¿å®Œæˆ!")
            print(f"âœ… æ•°æ®åŠ è½½: æˆåŠŸ")
            print(f"âœ… æ¨¡å‹è®­ç»ƒ: æˆåŠŸ")


            return True

        except Exception as e:
            print(f"\nâŒ æµæ°´çº¿æ‰§è¡Œå¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return False


